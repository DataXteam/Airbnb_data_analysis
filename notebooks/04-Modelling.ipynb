{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modeling\n",
    "\n",
    "**Goal:** Train, evaluate, tune, and select the best machine learning model to predict the log-transformed price (`log_price`) of Prague Airbnb listings as accurately as possible, based on the prepared dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Baselines\n",
    "*   Import necessary libraries for modeling and evaluation.\n",
    "*   Load the processed and scaled training/testing data splits.\n",
    "*   Load the saved scaler and feature list.\n",
    "*   Define evaluation metrics and a helper function for reporting on the original price scale.\n",
    "*   Establish baseline performance metrics (mean prediction and simple Linear Regression)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries\n",
    "Import libraries for data handling, modeling algorithms, evaluation metrics, cross-validation, and loading saved objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported for modeling.\n"
     ]
    }
   ],
   "source": [
    "# Data Handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib # For loading scaler/feature list\n",
    "\n",
    "# Modeling Algorithms\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.dummy import DummyRegressor # For mean baseline\n",
    "\n",
    "# Evaluation Metrics\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Cross-validation and Tuning\n",
    "from sklearn.model_selection import KFold, cross_val_score, RandomizedSearchCV \n",
    "# from sklearn.model_selection import GridSearchCV # Alternative tuner\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x) # More precision for metrics\n",
    "\n",
    "print(\"Libraries imported for modeling.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Processed Data and Preprocessors\n",
    "Load the scaled training and testing datasets (`X_train_scaled`, `X_test_scaled`, `y_train`, `y_test`) saved at the end of Data Preparation. Also load the fitted `StandardScaler` and the final feature list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data and preprocessors loaded successfully.\n",
      "X_train_scaled shape: (7014, 66)\n",
      "X_test_scaled shape : (1754, 66)\n",
      "y_train shape: (7014,)\n",
      "y_test shape : (1754,)\n",
      "\n",
      "Train data columns match the saved feature list.\n",
      "\n",
      "Head of X_train_scaled:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>host_acceptance_rate</th>\n",
       "      <th>host_identity_verified</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>maximum_nights</th>\n",
       "      <th>availability_30</th>\n",
       "      <th>availability_365</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>number_of_reviews_ltm</th>\n",
       "      <th>review_scores_rating</th>\n",
       "      <th>review_scores_location</th>\n",
       "      <th>review_scores_value</th>\n",
       "      <th>instant_bookable</th>\n",
       "      <th>calculated_host_listings_count_entire_homes</th>\n",
       "      <th>calculated_host_listings_count_private_rooms</th>\n",
       "      <th>calculated_host_listings_count_shared_rooms</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>num_amenities</th>\n",
       "      <th>amenity_wifi</th>\n",
       "      <th>amenity_kitchen</th>\n",
       "      <th>amenity_air_conditioning</th>\n",
       "      <th>amenity_heating</th>\n",
       "      <th>amenity_washer</th>\n",
       "      <th>amenity_dryer</th>\n",
       "      <th>amenity_tv</th>\n",
       "      <th>amenity_parking</th>\n",
       "      <th>amenity_pool</th>\n",
       "      <th>amenity_pets_allowed</th>\n",
       "      <th>amenity_long_term_stays_allowed</th>\n",
       "      <th>num_host_verifications</th>\n",
       "      <th>host_duration_days</th>\n",
       "      <th>days_since_last_review</th>\n",
       "      <th>has_reviews</th>\n",
       "      <th>calculated_host_listings_count_shared_rooms_log</th>\n",
       "      <th>bathrooms_log</th>\n",
       "      <th>calculated_host_listings_count_private_rooms_log</th>\n",
       "      <th>host_acceptance_rate_log</th>\n",
       "      <th>beds_log</th>\n",
       "      <th>days_since_last_review_log</th>\n",
       "      <th>number_of_reviews_log</th>\n",
       "      <th>bedrooms_log</th>\n",
       "      <th>reviews_per_month_log</th>\n",
       "      <th>accommodates_log</th>\n",
       "      <th>calculated_host_listings_count_entire_homes_log</th>\n",
       "      <th>number_of_reviews_ltm_log</th>\n",
       "      <th>host_response_time_Unknown</th>\n",
       "      <th>host_response_time_days_or_more</th>\n",
       "      <th>host_response_time_within_day</th>\n",
       "      <th>host_response_time_within_hour</th>\n",
       "      <th>host_response_time_within_hours</th>\n",
       "      <th>room_type_Entire_home/apt</th>\n",
       "      <th>room_type_Hotel_room</th>\n",
       "      <th>room_type_Private_room</th>\n",
       "      <th>room_type_Shared_room</th>\n",
       "      <th>neighbourhood_group_Near_Center_East</th>\n",
       "      <th>neighbourhood_group_Near_Center_West_South</th>\n",
       "      <th>neighbourhood_group_New_Town_Vinohrady</th>\n",
       "      <th>neighbourhood_group_North_West_Districts</th>\n",
       "      <th>neighbourhood_group_Old_Town_Center</th>\n",
       "      <th>neighbourhood_group_Outer_Districts</th>\n",
       "      <th>property_type_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7040</th>\n",
       "      <td>0.31773</td>\n",
       "      <td>0.12796</td>\n",
       "      <td>-1.00211</td>\n",
       "      <td>-0.14625</td>\n",
       "      <td>-0.43309</td>\n",
       "      <td>-0.39264</td>\n",
       "      <td>-0.39836</td>\n",
       "      <td>-0.23443</td>\n",
       "      <td>0.11789</td>\n",
       "      <td>-0.34667</td>\n",
       "      <td>-0.92162</td>\n",
       "      <td>-0.38376</td>\n",
       "      <td>-0.39253</td>\n",
       "      <td>0.41020</td>\n",
       "      <td>0.70862</td>\n",
       "      <td>0.67324</td>\n",
       "      <td>0.62997</td>\n",
       "      <td>-1.27978</td>\n",
       "      <td>-0.34365</td>\n",
       "      <td>-0.28196</td>\n",
       "      <td>-0.09380</td>\n",
       "      <td>0.10470</td>\n",
       "      <td>0.76782</td>\n",
       "      <td>0.11142</td>\n",
       "      <td>0.27675</td>\n",
       "      <td>0.49447</td>\n",
       "      <td>0.27406</td>\n",
       "      <td>0.47563</td>\n",
       "      <td>0.33138</td>\n",
       "      <td>0.57922</td>\n",
       "      <td>0.83073</td>\n",
       "      <td>-0.15181</td>\n",
       "      <td>-0.63003</td>\n",
       "      <td>0.84602</td>\n",
       "      <td>2.14201</td>\n",
       "      <td>1.30126</td>\n",
       "      <td>-0.34586</td>\n",
       "      <td>0.30193</td>\n",
       "      <td>-0.11009</td>\n",
       "      <td>-0.47959</td>\n",
       "      <td>-0.45942</td>\n",
       "      <td>0.30163</td>\n",
       "      <td>-0.07051</td>\n",
       "      <td>-0.68492</td>\n",
       "      <td>0.16380</td>\n",
       "      <td>-0.29696</td>\n",
       "      <td>0.42263</td>\n",
       "      <td>-0.33622</td>\n",
       "      <td>0.17524</td>\n",
       "      <td>0.79439</td>\n",
       "      <td>-0.25524</td>\n",
       "      <td>-0.12387</td>\n",
       "      <td>-0.21395</td>\n",
       "      <td>0.46501</td>\n",
       "      <td>-0.24755</td>\n",
       "      <td>0.42475</td>\n",
       "      <td>-0.09210</td>\n",
       "      <td>-0.39484</td>\n",
       "      <td>-0.09821</td>\n",
       "      <td>-0.50049</td>\n",
       "      <td>-0.31222</td>\n",
       "      <td>2.14633</td>\n",
       "      <td>-0.28823</td>\n",
       "      <td>-0.76678</td>\n",
       "      <td>-0.30585</td>\n",
       "      <td>0.80065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7863</th>\n",
       "      <td>0.37241</td>\n",
       "      <td>0.12796</td>\n",
       "      <td>0.22597</td>\n",
       "      <td>-0.05502</td>\n",
       "      <td>0.73766</td>\n",
       "      <td>-0.39264</td>\n",
       "      <td>-0.39836</td>\n",
       "      <td>0.21767</td>\n",
       "      <td>-0.34522</td>\n",
       "      <td>-1.18489</td>\n",
       "      <td>-1.24191</td>\n",
       "      <td>-1.46549</td>\n",
       "      <td>-0.22562</td>\n",
       "      <td>1.27716</td>\n",
       "      <td>0.57742</td>\n",
       "      <td>0.79933</td>\n",
       "      <td>0.62997</td>\n",
       "      <td>0.78139</td>\n",
       "      <td>-0.60287</td>\n",
       "      <td>-0.28196</td>\n",
       "      <td>-0.09380</td>\n",
       "      <td>1.62976</td>\n",
       "      <td>0.84291</td>\n",
       "      <td>0.11142</td>\n",
       "      <td>0.27675</td>\n",
       "      <td>-2.02237</td>\n",
       "      <td>0.27406</td>\n",
       "      <td>0.47563</td>\n",
       "      <td>0.33138</td>\n",
       "      <td>0.57922</td>\n",
       "      <td>0.83073</td>\n",
       "      <td>-0.15181</td>\n",
       "      <td>-0.63003</td>\n",
       "      <td>0.84602</td>\n",
       "      <td>-0.13436</td>\n",
       "      <td>-1.61776</td>\n",
       "      <td>-0.35023</td>\n",
       "      <td>0.30193</td>\n",
       "      <td>-0.11009</td>\n",
       "      <td>-0.47959</td>\n",
       "      <td>-0.45942</td>\n",
       "      <td>0.34406</td>\n",
       "      <td>0.54130</td>\n",
       "      <td>-1.45500</td>\n",
       "      <td>0.41736</td>\n",
       "      <td>-0.29696</td>\n",
       "      <td>1.46903</td>\n",
       "      <td>0.96261</td>\n",
       "      <td>-0.65080</td>\n",
       "      <td>1.13384</td>\n",
       "      <td>-0.25524</td>\n",
       "      <td>-0.12387</td>\n",
       "      <td>-0.21395</td>\n",
       "      <td>0.46501</td>\n",
       "      <td>-0.24755</td>\n",
       "      <td>0.42475</td>\n",
       "      <td>-0.09210</td>\n",
       "      <td>-0.39484</td>\n",
       "      <td>-0.09821</td>\n",
       "      <td>-0.50049</td>\n",
       "      <td>-0.31222</td>\n",
       "      <td>-0.46591</td>\n",
       "      <td>-0.28823</td>\n",
       "      <td>1.30415</td>\n",
       "      <td>-0.30585</td>\n",
       "      <td>-1.17634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7652</th>\n",
       "      <td>0.31773</td>\n",
       "      <td>0.12796</td>\n",
       "      <td>-0.37276</td>\n",
       "      <td>-0.70000</td>\n",
       "      <td>1.90841</td>\n",
       "      <td>1.84332</td>\n",
       "      <td>1.78027</td>\n",
       "      <td>1.12185</td>\n",
       "      <td>0.11789</td>\n",
       "      <td>-0.34667</td>\n",
       "      <td>-0.60133</td>\n",
       "      <td>-0.11105</td>\n",
       "      <td>-0.67626</td>\n",
       "      <td>-0.85084</td>\n",
       "      <td>0.80701</td>\n",
       "      <td>-3.40372</td>\n",
       "      <td>-2.29712</td>\n",
       "      <td>-1.27978</td>\n",
       "      <td>0.00199</td>\n",
       "      <td>-0.28196</td>\n",
       "      <td>-0.09380</td>\n",
       "      <td>-0.96671</td>\n",
       "      <td>0.39238</td>\n",
       "      <td>0.11142</td>\n",
       "      <td>0.27675</td>\n",
       "      <td>0.49447</td>\n",
       "      <td>0.27406</td>\n",
       "      <td>0.47563</td>\n",
       "      <td>0.33138</td>\n",
       "      <td>0.57922</td>\n",
       "      <td>0.83073</td>\n",
       "      <td>-0.15181</td>\n",
       "      <td>1.58724</td>\n",
       "      <td>0.84602</td>\n",
       "      <td>-0.13436</td>\n",
       "      <td>1.11990</td>\n",
       "      <td>-0.23744</td>\n",
       "      <td>0.30193</td>\n",
       "      <td>-0.11009</td>\n",
       "      <td>2.25335</td>\n",
       "      <td>-0.45942</td>\n",
       "      <td>0.30163</td>\n",
       "      <td>1.40360</td>\n",
       "      <td>0.76876</td>\n",
       "      <td>-1.49494</td>\n",
       "      <td>1.67274</td>\n",
       "      <td>-1.30581</td>\n",
       "      <td>1.79043</td>\n",
       "      <td>0.65344</td>\n",
       "      <td>-1.13301</td>\n",
       "      <td>-0.25524</td>\n",
       "      <td>-0.12387</td>\n",
       "      <td>-0.21395</td>\n",
       "      <td>0.46501</td>\n",
       "      <td>-0.24755</td>\n",
       "      <td>0.42475</td>\n",
       "      <td>-0.09210</td>\n",
       "      <td>-0.39484</td>\n",
       "      <td>-0.09821</td>\n",
       "      <td>-0.50049</td>\n",
       "      <td>3.20288</td>\n",
       "      <td>-0.46591</td>\n",
       "      <td>-0.28823</td>\n",
       "      <td>-0.76678</td>\n",
       "      <td>-0.30585</td>\n",
       "      <td>0.80065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      host_acceptance_rate  host_identity_verified  latitude  longitude  \\\n",
       "7040               0.31773                 0.12796  -1.00211   -0.14625   \n",
       "7863               0.37241                 0.12796   0.22597   -0.05502   \n",
       "7652               0.31773                 0.12796  -0.37276   -0.70000   \n",
       "\n",
       "      accommodates  bathrooms  bedrooms     beds  minimum_nights  \\\n",
       "7040      -0.43309   -0.39264  -0.39836 -0.23443         0.11789   \n",
       "7863       0.73766   -0.39264  -0.39836  0.21767        -0.34522   \n",
       "7652       1.90841    1.84332   1.78027  1.12185         0.11789   \n",
       "\n",
       "      maximum_nights  availability_30  availability_365  number_of_reviews  \\\n",
       "7040        -0.34667         -0.92162          -0.38376           -0.39253   \n",
       "7863        -1.18489         -1.24191          -1.46549           -0.22562   \n",
       "7652        -0.34667         -0.60133          -0.11105           -0.67626   \n",
       "\n",
       "      number_of_reviews_ltm  review_scores_rating  review_scores_location  \\\n",
       "7040                0.41020               0.70862                 0.67324   \n",
       "7863                1.27716               0.57742                 0.79933   \n",
       "7652               -0.85084               0.80701                -3.40372   \n",
       "\n",
       "      review_scores_value  instant_bookable  \\\n",
       "7040              0.62997          -1.27978   \n",
       "7863              0.62997           0.78139   \n",
       "7652             -2.29712          -1.27978   \n",
       "\n",
       "      calculated_host_listings_count_entire_homes  \\\n",
       "7040                                     -0.34365   \n",
       "7863                                     -0.60287   \n",
       "7652                                      0.00199   \n",
       "\n",
       "      calculated_host_listings_count_private_rooms  \\\n",
       "7040                                      -0.28196   \n",
       "7863                                      -0.28196   \n",
       "7652                                      -0.28196   \n",
       "\n",
       "      calculated_host_listings_count_shared_rooms  reviews_per_month  \\\n",
       "7040                                     -0.09380            0.10470   \n",
       "7863                                     -0.09380            1.62976   \n",
       "7652                                     -0.09380           -0.96671   \n",
       "\n",
       "      num_amenities  amenity_wifi  amenity_kitchen  amenity_air_conditioning  \\\n",
       "7040        0.76782       0.11142          0.27675                   0.49447   \n",
       "7863        0.84291       0.11142          0.27675                  -2.02237   \n",
       "7652        0.39238       0.11142          0.27675                   0.49447   \n",
       "\n",
       "      amenity_heating  amenity_washer  amenity_dryer  amenity_tv  \\\n",
       "7040          0.27406         0.47563        0.33138     0.57922   \n",
       "7863          0.27406         0.47563        0.33138     0.57922   \n",
       "7652          0.27406         0.47563        0.33138     0.57922   \n",
       "\n",
       "      amenity_parking  amenity_pool  amenity_pets_allowed  \\\n",
       "7040          0.83073      -0.15181              -0.63003   \n",
       "7863          0.83073      -0.15181              -0.63003   \n",
       "7652          0.83073      -0.15181               1.58724   \n",
       "\n",
       "      amenity_long_term_stays_allowed  num_host_verifications  \\\n",
       "7040                          0.84602                 2.14201   \n",
       "7863                          0.84602                -0.13436   \n",
       "7652                          0.84602                -0.13436   \n",
       "\n",
       "      host_duration_days  days_since_last_review  has_reviews  \\\n",
       "7040             1.30126                -0.34586      0.30193   \n",
       "7863            -1.61776                -0.35023      0.30193   \n",
       "7652             1.11990                -0.23744      0.30193   \n",
       "\n",
       "      calculated_host_listings_count_shared_rooms_log  bathrooms_log  \\\n",
       "7040                                         -0.11009       -0.47959   \n",
       "7863                                         -0.11009       -0.47959   \n",
       "7652                                         -0.11009        2.25335   \n",
       "\n",
       "      calculated_host_listings_count_private_rooms_log  \\\n",
       "7040                                          -0.45942   \n",
       "7863                                          -0.45942   \n",
       "7652                                          -0.45942   \n",
       "\n",
       "      host_acceptance_rate_log  beds_log  days_since_last_review_log  \\\n",
       "7040                   0.30163  -0.07051                    -0.68492   \n",
       "7863                   0.34406   0.54130                    -1.45500   \n",
       "7652                   0.30163   1.40360                     0.76876   \n",
       "\n",
       "      number_of_reviews_log  bedrooms_log  reviews_per_month_log  \\\n",
       "7040                0.16380      -0.29696                0.42263   \n",
       "7863                0.41736      -0.29696                1.46903   \n",
       "7652               -1.49494       1.67274               -1.30581   \n",
       "\n",
       "      accommodates_log  calculated_host_listings_count_entire_homes_log  \\\n",
       "7040          -0.33622                                          0.17524   \n",
       "7863           0.96261                                         -0.65080   \n",
       "7652           1.79043                                          0.65344   \n",
       "\n",
       "      number_of_reviews_ltm_log  host_response_time_Unknown  \\\n",
       "7040                    0.79439                    -0.25524   \n",
       "7863                    1.13384                    -0.25524   \n",
       "7652                   -1.13301                    -0.25524   \n",
       "\n",
       "      host_response_time_days_or_more  host_response_time_within_day  \\\n",
       "7040                         -0.12387                       -0.21395   \n",
       "7863                         -0.12387                       -0.21395   \n",
       "7652                         -0.12387                       -0.21395   \n",
       "\n",
       "      host_response_time_within_hour  host_response_time_within_hours  \\\n",
       "7040                         0.46501                         -0.24755   \n",
       "7863                         0.46501                         -0.24755   \n",
       "7652                         0.46501                         -0.24755   \n",
       "\n",
       "      room_type_Entire_home/apt  room_type_Hotel_room  room_type_Private_room  \\\n",
       "7040                    0.42475              -0.09210                -0.39484   \n",
       "7863                    0.42475              -0.09210                -0.39484   \n",
       "7652                    0.42475              -0.09210                -0.39484   \n",
       "\n",
       "      room_type_Shared_room  neighbourhood_group_Near_Center_East  \\\n",
       "7040               -0.09821                              -0.50049   \n",
       "7863               -0.09821                              -0.50049   \n",
       "7652               -0.09821                              -0.50049   \n",
       "\n",
       "      neighbourhood_group_Near_Center_West_South  \\\n",
       "7040                                    -0.31222   \n",
       "7863                                    -0.31222   \n",
       "7652                                     3.20288   \n",
       "\n",
       "      neighbourhood_group_New_Town_Vinohrady  \\\n",
       "7040                                 2.14633   \n",
       "7863                                -0.46591   \n",
       "7652                                -0.46591   \n",
       "\n",
       "      neighbourhood_group_North_West_Districts  \\\n",
       "7040                                  -0.28823   \n",
       "7863                                  -0.28823   \n",
       "7652                                  -0.28823   \n",
       "\n",
       "      neighbourhood_group_Old_Town_Center  \\\n",
       "7040                             -0.76678   \n",
       "7863                              1.30415   \n",
       "7652                             -0.76678   \n",
       "\n",
       "      neighbourhood_group_Outer_Districts  property_type_freq  \n",
       "7040                             -0.30585             0.80065  \n",
       "7863                             -0.30585            -1.17634  \n",
       "7652                             -0.30585             0.80065  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Head of y_train:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7040   7.51098\n",
       "7863   7.09755\n",
       "7652   8.41627\n",
       "Name: log_price, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define paths (relative to notebooks/ directory)\n",
    "data_path = '../data/processed/'\n",
    "model_path = '../model/'\n",
    "\n",
    "try:\n",
    "    # Load features and target\n",
    "    X_train_scaled = pd.read_parquet(data_path + 'X_train_scaled.parquet')\n",
    "    X_test_scaled = pd.read_parquet(data_path + 'X_test_scaled.parquet')\n",
    "    y_train = pd.read_parquet(data_path + 'y_train.parquet')['log_price'] # Extract Series\n",
    "    y_test = pd.read_parquet(data_path + 'y_test.parquet')['log_price'] # Extract Series\n",
    "    \n",
    "    # Load preprocessors\n",
    "    scaler = joblib.load(model_path + 'standard_scaler.joblib')\n",
    "    final_features = joblib.load(model_path + 'final_feature_list.joblib')\n",
    "\n",
    "    print(\"Processed data and preprocessors loaded successfully.\")\n",
    "    \n",
    "    # Verify shapes and columns\n",
    "    print(f\"X_train_scaled shape: {X_train_scaled.shape}\")\n",
    "    print(f\"X_test_scaled shape : {X_test_scaled.shape}\")\n",
    "    print(f\"y_train shape: {y_train.shape}\")\n",
    "    print(f\"y_test shape : {y_test.shape}\")\n",
    "    \n",
    "    # Check if columns match saved list\n",
    "    if list(X_train_scaled.columns) == final_features:\n",
    "        print(\"\\nTrain data columns match the saved feature list.\")\n",
    "    else:\n",
    "        print(\"\\nWarning: Train data columns mismatch saved feature list!\")\n",
    "        \n",
    "    # Display head of loaded data\n",
    "    print(\"\\nHead of X_train_scaled:\")\n",
    "    display(X_train_scaled.head(3))\n",
    "    print(\"\\nHead of y_train:\")\n",
    "    display(y_train.head(3))\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading data: {e}. Make sure preprocessing steps were run and files saved correctly.\")\n",
    "    # Set variables to None to prevent errors in subsequent cells\n",
    "    X_train_scaled, X_test_scaled, y_train, y_test, scaler, final_features = [None]*6\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during loading: {e}\")\n",
    "    X_train_scaled, X_test_scaled, y_train, y_test, scaler, final_features = [None]*6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Evaluation Metrics & Function\n",
    "Define the primary metric for cross-validation (`neg_root_mean_squared_error` on log scale) and a helper function to evaluate performance on the original price scale (RMSE, MAE, R²)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation metric and helper function defined.\n"
     ]
    }
   ],
   "source": [
    "# M1.3 Define Evaluation Metrics & Function\n",
    "\n",
    "# Primary metric for CV (lower is better, hence negative for maximization)\n",
    "CV_SCORING = 'neg_root_mean_squared_error'\n",
    "\n",
    "# Helper function to evaluate on original price scale\n",
    "def evaluate_on_original_scale(y_true_log, y_pred_log, model_name=\"Model\"):\n",
    "    \"\"\"Calculates RMSE, MAE, R2 on the original price scale.\"\"\"\n",
    "    \n",
    "    # Inverse transform from log scale\n",
    "    y_true_orig = np.expm1(y_true_log)\n",
    "    y_pred_orig = np.expm1(y_pred_log)\n",
    "    \n",
    "    # Handle potential negative predictions after expm1\n",
    "    y_pred_orig[y_pred_orig < 0] = 0 \n",
    "    \n",
    "    # Calculate metrics using MSE + sqrt\n",
    "    mse = mean_squared_error(y_true_orig, y_pred_orig) \n",
    "    rmse = np.sqrt(mse) # Calculate RMSE manually\n",
    "    mae = mean_absolute_error(y_true_orig, y_pred_orig)\n",
    "    r2 = r2_score(y_true_orig, y_pred_orig)\n",
    "    \n",
    "    print(f\"--- {model_name} Performance (Original Price Scale) ---\")\n",
    "    print(f\"RMSE: {rmse:.2f}\") \n",
    "    print(f\"MAE:  {mae:.2f}\")  \n",
    "    print(f\"R^2:  {r2:.3f}\")  \n",
    "    print(\"----------------------------------------------------\")\n",
    "    \n",
    "    return {'RMSE': rmse, 'MAE': mae, 'R2': r2}\n",
    "\n",
    "print(\"Evaluation metric and helper function defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Observation:* The primary scoring metric for cross-validation (`neg_root_mean_squared_error`) is set. A helper function `evaluate_on_original_scale` was created to easily calculate and report RMSE, MAE, and R² on the original price scale by applying `np.expm1` to the log-scale predictions and true values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establish Baseline Performance\n",
    "Calculate baseline metrics using two simple strategies: predicting the mean and using basic Linear Regression with cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Baseline 1: Predicting Mean ---\n",
      "Predicting constant mean log_price: 7.539\n",
      "--- Mean Baseline Performance (Original Price Scale) ---\n",
      "RMSE: 4833.50\n",
      "MAE:  1386.85\n",
      "R^2:  -0.022\n",
      "----------------------------------------------------\n",
      "\n",
      "--- Baseline 2: Linear Regression (5-Fold CV) ---\n",
      "Mean CV RMSE (log scale): 0.4466 (+/- 0.0202)\n",
      "(Lower RMSE is better)\n"
     ]
    }
   ],
   "source": [
    "# M1.4 Establish Baseline Performance \n",
    "# (No changes needed here if M1.3 function uses the workaround)\n",
    "if 'y_train' in locals() and 'y_test' in locals() and y_train is not None and y_test is not None:\n",
    "\n",
    "    # --- Baseline 1: Mean Prediction ---\n",
    "    print(\"--- Baseline 1: Predicting Mean ---\")\n",
    "    mean_log_price_train = y_train.mean()\n",
    "    y_pred_mean_log = np.full_like(y_test, fill_value=mean_log_price_train)\n",
    "    \n",
    "    print(f\"Predicting constant mean log_price: {mean_log_price_train:.3f}\")\n",
    "    # This call now uses the evaluate_on_original_scale function with the workaround\n",
    "    baseline_mean_results = evaluate_on_original_scale(y_test, y_pred_mean_log, model_name=\"Mean Baseline\") \n",
    "\n",
    "    # --- Baseline 2: Linear Regression (Cross-Validated) ---\n",
    "    print(\"\\n--- Baseline 2: Linear Regression (5-Fold CV) ---\")\n",
    "    cv_strategy = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    lr_baseline = LinearRegression()\n",
    "    \n",
    "    # This uses CV_SCORING='neg_root_mean_squared_error' which should work fine in cross_val_score\n",
    "    lr_cv_scores = cross_val_score(\n",
    "        lr_baseline, \n",
    "        X_train_scaled, \n",
    "        y_train, \n",
    "        cv=cv_strategy, \n",
    "        scoring=CV_SCORING,\n",
    "        n_jobs=-1 \n",
    "    )\n",
    "    \n",
    "    mean_cv_rmse_log = -lr_cv_scores.mean() \n",
    "    std_cv_rmse_log = lr_cv_scores.std()\n",
    "    \n",
    "    print(f\"Mean CV RMSE (log scale): {mean_cv_rmse_log:.4f} (+/- {std_cv_rmse_log:.4f})\")\n",
    "    print(\"(Lower RMSE is better)\")\n",
    "\n",
    "else:\n",
    "    print(\"Error: Training/testing data not available for baseline calculation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Candidate Model Training & Evaluation (Initial CV)\n",
    "\n",
    "In this phase, we train several different types of regression models using their default settings and evaluate their baseline performance using cross-validation on the training data. The goal is to get an initial estimate of how well each model type performs on this specific dataset and identify promising candidates for further tuning. We will:\n",
    "*   Select a diverse set of candidate models (Linear, Tree Ensembles).\n",
    "*   Use K-Fold cross-validation to evaluate each model's performance based on Root Mean Squared Error (RMSE) on the log-price scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Candidate Models\n",
    "Define a dictionary containing instances of the regression models we want to evaluate initially. We include regularized linear models and popular tree-based ensembles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 5 candidate models for initial evaluation:\n",
      "['Ridge', 'Lasso', 'RandomForest', 'XGBoost', 'LightGBM']\n"
     ]
    }
   ],
   "source": [
    "# M2.1 Select Candidate Models\n",
    "if ('LinearRegression' not in locals() or # Check if imports might have been cleared\n",
    "    'Ridge' not in locals() or \n",
    "    'Lasso' not in locals() or \n",
    "    'RandomForestRegressor' not in locals() or \n",
    "    'XGBRegressor' not in locals() or \n",
    "    'LGBMRegressor' not in locals()):\n",
    "    # Re-import if necessary (e.g., if running notebook non-linearly)\n",
    "    print(\"Re-importing model classes...\")\n",
    "    from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from xgboost import XGBRegressor\n",
    "    from lightgbm import LGBMRegressor\n",
    "\n",
    "# Define models to evaluate with default parameters\n",
    "# Use random_state for models that have it for reproducibility\n",
    "models_to_evaluate = {\n",
    "    # \"LinearRegression\": LinearRegression(), # Already used as baseline M1.4\n",
    "    \"Ridge\": Ridge(random_state=42),\n",
    "    \"Lasso\": Lasso(random_state=42),\n",
    "    \"RandomForest\": RandomForestRegressor(random_state=42, n_jobs=-1), # Use n_jobs=-1 for speed\n",
    "    \"XGBoost\": XGBRegressor(random_state=42, n_jobs=-1),\n",
    "    \"LightGBM\": LGBMRegressor(random_state=42, n_jobs=-1, verbosity=-1) # Suppress LightGBM verbosity\n",
    "}\n",
    "\n",
    "print(f\"Selected {len(models_to_evaluate)} candidate models for initial evaluation:\")\n",
    "print(list(models_to_evaluate.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Observation:* A dictionary `models_to_evaluate` was created containing instances of Ridge, Lasso, RandomForestRegressor, XGBRegressor, and LGBMRegressor, using default hyperparameters and fixed random states where applicable. These represent a good mix of linear and powerful ensemble methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Cross-Validation\n",
    "Perform 5-Fold Cross-Validation for each candidate model on the scaled training data (`X_train_scaled`, `y_train`) using negative RMSE as the scoring metric. Record and display the mean and standard deviation of the scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing KFold CV strategy (5 splits, shuffled).\n",
      "\n",
      "Performing 5-Fold Cross-Validation for each model...\n",
      "  Evaluating Ridge...\n",
      "    Mean CV RMSE (log scale): 0.4466 (+/- 0.0202)\n",
      "  Evaluating Lasso...\n",
      "    Mean CV RMSE (log scale): 0.6663 (+/- 0.0152)\n",
      "  Evaluating RandomForest...\n",
      "    Mean CV RMSE (log scale): 0.3996 (+/- 0.0083)\n",
      "  Evaluating XGBoost...\n",
      "    Mean CV RMSE (log scale): 0.3883 (+/- 0.0155)\n",
      "  Evaluating LightGBM...\n",
      "    Mean CV RMSE (log scale): 0.3769 (+/- 0.0143)\n",
      "\n",
      "Initial Cross-Validation complete.\n",
      "\n",
      "--- Initial Model Performance Comparison (Mean CV RMSE on Log Scale) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_rmse</th>\n",
       "      <th>std_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.37690</td>\n",
       "      <td>0.01435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.38833</td>\n",
       "      <td>0.01546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.39960</td>\n",
       "      <td>0.00832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.44656</td>\n",
       "      <td>0.02021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>0.66625</td>\n",
       "      <td>0.01515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             mean_rmse std_rmse\n",
       "LightGBM       0.37690  0.01435\n",
       "XGBoost        0.38833  0.01546\n",
       "RandomForest   0.39960  0.00832\n",
       "Ridge          0.44656  0.02021\n",
       "Lasso          0.66625  0.01515"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# M2.2 Initial Cross-Validation\n",
    "if ('models_to_evaluate' in locals() and 'X_train_scaled' in locals() and 'y_train' in locals() and\n",
    "    X_train_scaled is not None and y_train is not None and models_to_evaluate):\n",
    "    \n",
    "    # Define CV strategy (can reuse from baseline)\n",
    "    if 'cv_strategy' not in locals(): # Define if not already present from M1.4\n",
    "        cv_strategy = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        print(\"Defined KFold CV strategy (5 splits, shuffled).\")\n",
    "    else:\n",
    "        print(\"Using existing KFold CV strategy (5 splits, shuffled).\")\n",
    "\n",
    "    # Store results\n",
    "    cv_results = {}\n",
    "    \n",
    "    print(\"\\nPerforming 5-Fold Cross-Validation for each model...\")\n",
    "\n",
    "    for model_name, model in models_to_evaluate.items():\n",
    "        print(f\"  Evaluating {model_name}...\")\n",
    "        try:\n",
    "            # Perform cross-validation\n",
    "            # Scores are negative RMSE on log scale\n",
    "            cv_scores = cross_val_score(\n",
    "                model, \n",
    "                X_train_scaled, \n",
    "                y_train, \n",
    "                cv=cv_strategy, \n",
    "                scoring=CV_SCORING, # Defined in M1.3 as 'neg_root_mean_squared_error'\n",
    "                n_jobs=-1 # Use all available CPU cores\n",
    "            )\n",
    "            \n",
    "            # Store mean and std dev (convert neg_rmse back to positive rmse)\n",
    "            mean_rmse = -cv_scores.mean()\n",
    "            std_rmse = cv_scores.std()\n",
    "            cv_results[model_name] = {'mean_rmse': mean_rmse, 'std_rmse': std_rmse, 'scores': -cv_scores}\n",
    "            \n",
    "            print(f\"    Mean CV RMSE (log scale): {mean_rmse:.4f} (+/- {std_rmse:.4f})\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"    Error evaluating {model_name}: {e}\")\n",
    "            cv_results[model_name] = {'mean_rmse': np.inf, 'std_rmse': np.nan, 'scores': []} # Record error\n",
    "\n",
    "    print(\"\\nInitial Cross-Validation complete.\")\n",
    "\n",
    "    # Display results sorted by mean RMSE (lower is better)\n",
    "    if cv_results:\n",
    "        print(\"\\n--- Initial Model Performance Comparison (Mean CV RMSE on Log Scale) ---\")\n",
    "        results_df = pd.DataFrame(cv_results).T[['mean_rmse', 'std_rmse']].sort_values('mean_rmse')\n",
    "        display(results_df)\n",
    "        print(\"-----------------------------------------------------------------------\")\n",
    "\n",
    "else:\n",
    "    print(\"Error: Prerequisite variables (models, data) not found or empty.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
